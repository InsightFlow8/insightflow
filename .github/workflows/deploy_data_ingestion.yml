name: Deploy Data Ingestion Infrastructure

on:
  workflow_dispatch:
    inputs:
      trigger_etl_after:
        description: 'Trigger ETL pipeline after data ingestion'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      clean_state_first:
        description: 'Clean Terraform state before deployment (use if AWS resources were manually deleted)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
  push:
    branches: [main, IF-25-raw-data-ETL]
    paths:
      - 'terraform/dev/main.tf'
      - 'terraform/dev/variables.tf'
      - 'terraform/dev/terraform.tfvars'
      - 'terraform/modules/s3_buckets/**'
      - 'terraform/modules/vpc/**'
      - 'terraform/modules/rds_postgresql/**'
      - 'terraform/modules/ec2/**'
      - 'terraform/modules/glue_tables/**'
      - 'terraform/modules/glue_tables_etl/**'
      - 'terraform/modules/data_ingestion/batch/**'
      - '.github/workflows/deploy_data_ingestion.yml'
      - 'terraform/assets/**'
  workflow_call:
    # Allow this workflow to be called by other workflows

permissions:
  contents: read
  actions: write  # Allow triggering other workflows

jobs:
  terraform:
    name: Deploy Data Ingestion Infrastructure
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ap-southeast-2

      # AWS Configuration
      TF_VAR_aws_region: ap-southeast-2
      TF_VAR_raw_bucket: insightflow-dev-raw-bucket
      TF_VAR_clean_bucket: insightflow-dev-clean-bucket
      TF_VAR_curated_bucket: insightflow-dev-curated-bucket
      TF_VAR_scripts_bucket: insightflow-dev-scripts-bucket

      # Snowflake Configuration
      TF_VAR_snowflake_user: ${{ secrets.SNOWFLAKE_USER }}
      TF_VAR_snowflake_password: ${{ secrets.SNOWFLAKE_PASSWORD }}
      TF_VAR_snowflake_account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      TF_VAR_snowflake_warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      TF_VAR_snowflake_role: ${{ secrets.SNOWFLAKE_ROLE }}
      TF_VAR_snowflake_secret_name: snowflake-insightflow

      # Database Configuration
      TF_VAR_db_name: insightflow_imba
      TF_VAR_db_username: ${{ secrets.DB_USERNAME }}
      TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}

      # EC2 Configuration
      TF_VAR_ami_id: ami-00839deb72faa8a04
      TF_VAR_instance_type: t2.micro
      TF_VAR_key_name: de_insightflow_ec2

      # S3 Configuration
      TF_VAR_raw_prefix: data/batch
      TF_VAR_aws_az: ap-southeast-2a

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ">= 1.7.5"

      - name: Terraform Init
        run: terraform init -backend-config="bucket=insightflow-dev-imba-group-state" -backend-config="key=state/terraform.tfstate" -backend-config="region=ap-southeast-2" -backend-config="dynamodb_table=insightflow_imba_group"
        working-directory: terraform/dev

      - name: Check and Force Unlock State (if needed)
        run: |
          # Check if state is locked and try to unlock
          echo "Checking for state locks..."
          
          # Try a quick plan to see if state is locked
          if ! terraform plan -input=false -lock-timeout=10s -target=data.aws_caller_identity.current 2>/dev/null; then
            echo "‚ö†Ô∏è State appears to be locked. Attempting to retrieve lock info..."
            
            # Try to get lock info and extract lock ID
            LOCK_OUTPUT=$(terraform plan -input=false 2>&1 || true)
            LOCK_ID=$(echo "$LOCK_OUTPUT" | grep -oP 'ID:\s+\K[a-f0-9-]+' | head -1)
            
            if [ ! -z "$LOCK_ID" ]; then
              echo "üîì Found lock ID: $LOCK_ID. Attempting to force unlock..."
              terraform force-unlock -force "$LOCK_ID" || echo "Failed to unlock, but continuing..."
            else
              echo "‚ö†Ô∏è Could not extract lock ID from error output"
            fi
          else
            echo "‚úÖ No state lock detected"
          fi
        working-directory: terraform/dev
        continue-on-error: true

      - name: Diagnose Terraform State
        run: |
          echo "üîç === TERRAFORM STATE DIAGNOSIS ==="
          echo "üìä Current state summary:"
          terraform state list || echo "No resources in state"
          
          echo ""
          echo "üîç Checking for RDS resources in state:"
          terraform state list | grep -i rds || echo "No RDS resources in state"
          
          echo ""
          echo "üîç Checking for VPC resources in state:"
          terraform state list | grep -i vpc || echo "No VPC resources in state"
          
          echo ""
          echo "üîç Checking for S3 resources in state:"
          terraform state list | grep -i s3 || echo "No S3 resources in state"
          
          echo ""
          echo "üìä State file info:"
          terraform state pull | jq '.version, .terraform_version, .resources | length' 2>/dev/null || echo "Could not parse state file"
          
          echo "üîç === END DIAGNOSIS ==="
        working-directory: terraform/dev
        continue-on-error: true

      - name: Clean Terraform State (if requested)
        if: github.event.inputs.clean_state_first == 'true'
        run: |
          echo "üßπ === CLEANING TERRAFORM STATE ==="
          echo "‚ö†Ô∏è WARNING: This will remove all resources from Terraform state!"
          echo "üîÑ Current resources in state:"
          terraform state list
          
          echo ""
          echo "üßπ Removing all resources from state..."
          
          # Get list of all resources and remove them one by one
          terraform state list | while read resource; do
            if [ ! -z "$resource" ]; then
              echo "üóëÔ∏è Removing $resource from state..."
              terraform state rm "$resource" || echo "Failed to remove $resource"
            fi
          done
          
          echo ""
          echo "‚úÖ State cleaning completed. Remaining resources:"
          terraform state list || echo "No resources remain in state"
          echo "üßπ === CLEANING COMPLETED ==="
        working-directory: terraform/dev
        continue-on-error: true
      
      - name: Terraform Format Check
        run: terraform fmt -check
        working-directory: terraform/dev

      # Create Lambda deployment packages
      # - name: Create Lambda S3 to RDS Raw deployment package
      #   run: |
      #     cd functions/modules/data_sync/raw
      #     zip -r ../../../../terraform/assets/lambda_s3_to_rds_raw.zip lambda_s3_to_rds_raw.py
      #   shell: bash

      # --- S3 Buckets ---
      - name: Terraform Plan (S3 Buckets Only)
        run: terraform plan -input=false -target=module.s3_buckets
        working-directory: terraform/dev

      - name: Terraform Apply (S3 Buckets Only) with Retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            cd terraform/dev
            terraform apply -auto-approve -target=module.s3_buckets

      # --- VPC ---
      - name: Terraform Plan (VPC Only)
        run: terraform plan -input=false -target=module.vpc
        working-directory: terraform/dev

      - name: Terraform Apply (VPC Only) with Retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            cd terraform/dev
            terraform apply -auto-approve -target=module.vpc

      # --- RDS PostgreSQL ---
      - name: Import existing DB subnet group if exists
        run: |
          echo "üîç Checking if DB subnet group exists..."
          if aws rds describe-db-subnet-groups --db-subnet-group-name insightflow-dev-postgres-subnet-group >/dev/null 2>&1; then
            echo "üì¶ DB subnet group exists, attempting to import..."
            terraform import module.rds_postgresql.aws_db_subnet_group.postgres insightflow-dev-postgres-subnet-group || echo "‚ö†Ô∏è Import failed or resource already in state"
          else
            echo "‚úÖ No existing DB subnet group found, will create new one"
          fi
        working-directory: terraform/dev

      - name: Terraform Plan (RDS PostgreSQL Only)
        run: terraform plan -input=false -target=module.rds_postgresql
        working-directory: terraform/dev

      - name: Terraform Apply (RDS PostgreSQL Only) with Retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 15
          max_attempts: 3
          retry_wait_seconds: 60
          command: |
            cd terraform/dev
            terraform apply -auto-approve -target=module.rds_postgresql

      # --- EC2 ---
      - name: Terraform Plan (EC2 Only)
        run: terraform plan -input=false -target=module.ec2
        working-directory: terraform/dev

      - name: Terraform Apply (EC2 Only) with Retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            cd terraform/dev
            terraform apply -auto-approve -target=module.ec2
      
      # --- Glue Tables ---
      - name: Terraform Plan (Glue Tables Only)
        run: terraform plan -input=false -target=module.glue_tables
        working-directory: terraform/dev

      - name: Terraform Apply (Glue Tables Only)
        run: |
          cd terraform/dev
          terraform apply -auto-approve -target=module.glue_tables
      
      # --- Batch Ingestion ---
      - name: Terraform Plan (Batch Ingestion Only)
        run: terraform plan -input=false -target=module.batch_ingestion
        working-directory: terraform/dev

      - name: Terraform Apply (Batch Ingestion Only) with Retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 15
          max_attempts: 3
          retry_wait_seconds: 60
          command: |
            cd terraform/dev
            terraform apply -auto-approve -target=module.batch_ingestion

      # =============================
      # Optional: Trigger ETL Pipeline
      # =============================
      - name: Trigger ETL Pipeline (Optional)
        if: github.event.inputs.trigger_etl_after == 'true'
        uses: actions/github-script@v6
        with:
          script: |
            const result = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'deploy_etl_pipeline.yml',
              ref: context.ref,
              inputs: {
                skip_prerequisites_check: 'true'
              }
            });
            console.log('‚úÖ ETL pipeline workflow triggered successfully');

      # =============================
      # Temporarily Disabled Modules
      # =============================
      # NOTE: The following modules are commented out and can be enabled when needed

      # --- Streaming Ingestion (Temporarily Disabled) ---
      # - name: Terraform Plan (Streaming Ingestion Only)
      #   run: terraform plan -input=false -target=module.streaming_ingestion
      #   working-directory: terraform/dev

      # - name: Terraform Apply (Streaming Ingestion Only) with Retry
      #   uses: nick-fields/retry@v3
      #   with:
      #     timeout_minutes: 15
      #     max_attempts: 3
      #     retry_wait_seconds: 60
      #     command: |
      #       cd terraform/dev
      #       terraform apply -auto-approve -target=module.streaming_ingestion

      # --- Glue Crawler Raw (Temporarily Disabled) ---
      # - name: Terraform Plan (Glue Crawler Raw Only)
      #   run: terraform plan -input=false -target=module.glue_crawler_raw
      #   working-directory: terraform/dev

      # - name: Terraform Apply (Glue Crawler Raw Only) with Retry
      #   uses: nick-fields/retry@v3
      #   with:
      #     timeout_minutes: 15
      #     max_attempts: 3
      #     retry_wait_seconds: 60
      #     command: |
      #       cd terraform/dev
      #       terraform apply -auto-approve -target=module.glue_crawler_raw

      # --- Data Sync Raw (Temporarily Disabled) ---
      # - name: Terraform Plan (Data Sync Raw Only)
      #   run: terraform plan -input=false -target=module.data_sync_raw
      #   working-directory: terraform/dev

      # - name: Terraform Apply (Data Sync Raw Only) with Retry
      #   uses: nick-fields/retry@v3
      #   with:
      #     timeout_minutes: 15
      #     max_attempts: 3
      #     retry_wait_seconds: 60
      #     command: |
      #       cd terraform/dev
      #       terraform apply -auto-approve -target=module.data_sync_raw